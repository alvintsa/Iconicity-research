{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEjvwRfBSiOF"
   },
   "source": [
    "# Distributional assumption -- The distribution includes biases!\n",
    "\n",
    "Word vectors encode the linguistic contexts in which words appear. We can therefore ask how much linguistic bias -- which echoes societal biases -- is encoded in word vectors. Because much of web text is written by white, heterosexual North American men, as well as their Western European counterparts, the texts include biases that get encoded via distributional semantics methods.\n",
    "\n",
    "Societal biases include, but are not exclusive to\n",
    "\n",
    "* race\n",
    "* ethnicity\n",
    "* gender\n",
    "* sexuality\n",
    "* disabled status\n",
    "* age\n",
    "* intersections of all of these\n",
    "\n",
    "We know that neural language models produce text that amplifies these biases. For example, recent studies suggest that neural language models and chat systems like ChatGPT have a predominantly \"cool (white, affluent) mom\" orientation toward social problems. The models in production today have lots of bumpers to prevent producing racist, sexist, etc. text.\n",
    "\n",
    "For this, I will show you a cool projection method called \"subspace\" analysis, which produces a vector between two end-points.\n",
    "\n",
    "One of the first places studying gender bias in word vectors was done was in [Bolukbası et al. (2016)](https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf) who used a combination of:\n",
    "\n",
    "* Static word vectors from `word2vec`\n",
    "* Difference vectors between two \"endpoints\" of a binary spectrum (masculine <--> feminine)\n",
    "* Principal components analysis over that endpoint\n",
    "* The above steps produce a \"gender subspace\" vector\n",
    "* Compute similarity between each vector for an occupation -- which can be biased toward different genders to different degrees, and verified with census data -- and the gender subspace vector\n",
    "\n",
    "For our experiment, we will load in some vectors from `spaCy` and quantify the degree to which gender bias exists for some specific words:\n",
    "\n",
    "```python\n",
    "pairs = [\n",
    "  ('he', 'she'),\n",
    "  ('his', 'hers'),\n",
    "  ('him', 'her'),\n",
    "  ('his', 'her'),\n",
    "  ('John', 'Mary'),\n",
    "  ('himself', 'herself'),\n",
    "  ('father', 'mother'),\n",
    "  ('guy', 'gal'),\n",
    "  ('boy', 'girl'),\n",
    "  ('male', 'female')\n",
    "]\n",
    "```\n",
    "\n",
    "### Food for thought\n",
    "* Can you think of other pairs of words that might be useful here? (brother, sister), (wife, husband), (doctor, nurse) ?\n",
    "* What about other dimensions from one end to another might be able to use this method? age - young <--> old, first name last name\n",
    "* How can these \"endpoints\" be used for answering questions other than bias? maybe it can look into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTgj2WIslmcF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "! python -m spacy download en_core_web_md\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD # to project down into smaller dimension\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b84SCsMXVvX"
   },
   "source": [
    "## Get occupations\n",
    "\n",
    "There are lots of ways to get career or occupational bias. Here, we download a dataset that has lots of different biases -- gender, race, ethnicity -- and was used to study bias in GPT-2. We can check that the Bolukbası method correlates with:\n",
    "\n",
    "- The gender bias in US Census data\n",
    "- The gender bias that GPT-2 produces\n",
    "\n",
    "https://github.com/oxai/intersectional_gpt2\n",
    "\n",
    "Data:\n",
    "https://github.com/oxai/intersectional_gpt2/blob/master/data/GPT-2/US_data/us_rows_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "DRKauB4wXPa4",
    "outputId": "10362b3c-e8e3-4ec1-c47b-4b359a303b82"
   },
   "outputs": [],
   "source": [
    "# upload the file\n",
    "df = pd.read_csv(\"documents/gpt_vs_us_data.csv\")\n",
    "df.head()\n",
    "\n",
    "# us_white_F is average bias in the census for white women\n",
    "# gpt_white_F is the average bias produced by GPT-2\n",
    "# ask dr jacobs what this means ~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_row(frame, field): # extract all data from a specific row in frame\n",
    "    result = []\n",
    "    for i, row in frame.iterrows():\n",
    "      row_val = row[field]\n",
    "      val_split = row_val.split(\"/\") # some data entries have multiple names separated by a \"/\"\n",
    "      for vals in val_split:\n",
    "        result.append(vals.strip()) # append to result array\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = extract_row(df, \"job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MEp5izlXW8H"
   },
   "source": [
    "## Define the words used for the \"endpoints\" of the projection\n",
    "\n",
    "The idea here is that if we compute the \"difference\" (subtraction) between \"masculine\" vectors and \"feminine\" vectors, we can compute the subspace that corresponds to the axes that are correlated with some linguistic dimension of bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnsHaBftSeN6"
   },
   "outputs": [],
   "source": [
    "pairs = [\n",
    "  ('he', 'she'),\n",
    "  ('his', 'hers'),\n",
    "  ('him', 'her'),\n",
    "  ('his', 'her'),\n",
    "  ('John', 'Mary'),\n",
    "  ('himself', 'herself'),\n",
    "  ('father', 'mother'),\n",
    "  ('guy', 'gal'),\n",
    "  ('boy', 'girl'),\n",
    "  ('male', 'female'),\n",
    "  ('masculine', 'feminine'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoints(model, pairs): # get difference vectors between pairs, create endpoints\n",
    "    diff_vectors = [normalize(model(x).vector.reshape(1, -1) - model(y).vector.reshape(1, -1))[0] for x, y in pairs] #model(x) gets word embeddings from model\n",
    "    return diff_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_vectors = create_endpoints(nlp, pairs)\n",
    "diff_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1Mm0TXtmKCN"
   },
   "source": [
    "# Learn the subspace using PCA\n",
    "\n",
    "PCA learns the dominant dimensions that characterize a space. If we project to a single dimension, this will result in one \"component\" that characterizes the differences between \"masculine\" vectors and \"feminine\" vectors.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/GaussianScatterPCA.svg/1920px-GaussianScatterPCA.svg.png\" width=400>\n",
    "\n",
    "PCA demonstration, Wikipeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "v8BihqbAdg2A",
    "outputId": "32105dfd-ba09-4d95-f86d-a1c3a06fa335"
   },
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(n_components=1) # one gender dimension\n",
    "pca.fit(diff_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64E1RbT3zF5V"
   },
   "source": [
    "As an annoying implementational detail, Bolukbası normalize word vectors to the unit circle -- but this might not be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uc_vectors(model, vectors): # get unit circle vectors\n",
    "    uc_vectors = [normalize(model(vector).vector.reshape(1, -1))[0] for vector in vectors]\n",
    "    return uc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vectors = compute_uc_vectors(nlp, jobs)\n",
    "job_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hC7OJGcmNSz"
   },
   "source": [
    "# Compute the bias scores using cosine similarity\n",
    "\n",
    "We can look at how much the learned axis above \"weighs\" in the same direction as any particular job word vector. Above, we extract the vectors for a bunch of job titles, and we'll compute the cosine similarity (angle difference) between the \"gender subspace\" vector and the job title vector.\n",
    "\n",
    "The numbers weigh on the differences -- we subtracted feminine from masculine, so higher values indicate more feminine \"loadings\" and lower values are more \"masculine.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(extracted, vectors): # get bias scores from df data, and created masculine/feminine subspace\n",
    "    bias_scores = []\n",
    "    for i, vector in enumerate(vectors):\n",
    "        vector_data = extracted[i]\n",
    "    bias_scores.append((vector_data, cosine(vector, normalize(pca.components_).reshape(-1)))) # make this its own function\n",
    "    return bias_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = pca.transform(job_vectors).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = list(zip(scores, jobs))\n",
    "scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AwHnbHMitx8"
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_list, columns=['bias', 'job']) # create our own df from subsapce and jobs data\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDNB3oMh0uz1"
   },
   "source": [
    "### Correlation of spaCy vectors to GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_plot(df_one, df_two, x_axis, y_axis, label, x_axisName, y_axisName):\n",
    "    plot = (ggplot(df_one.merge(df_two),\n",
    "       aes(x=x_axis, y=y_axis, label=label)) + geom_label() + theme_bw()\n",
    "       + xlab(x_axisName)\n",
    "       + ylab(y_axisName))\n",
    "    return plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.merge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(scores_df, df, \"bias\", \"gpt_white_F\", \"job\", \"spaCy vector bias, Bolukbasi method\", \"GPT vector bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2QPh2hP0yPX"
   },
   "source": [
    "### Correlation of spaCy vectors to US Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(scores_df, df, \"bias\", \"us_white_F\", \"job\", \"spaCy vector bias, Bolukbasi method\", \"US census bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Extracted dataset that studied GPT-2 bias\n",
    "2. Define endpoints for projection using spacy model. We used vectors that were pairs of opposite sides to each other. (masculine, feminine). We subtracted\n",
    "them. This produces difference vectors that we use as endpoints to project a subspace, which includes one \"component\" that characterizes the difference between\n",
    "masculine and feminine vectors. Now we have a subspace to utilize that has masculine and feminine endpoints, as well as one component that has the differences.\n",
    "3. We now compute the bias scores using cosine similarity - angle difference (the component). \n",
    "4. We compute the cosine similarity between the gender subspace and the job title vector.\n",
    "5. The numbers weigh on the differences -- we subtracted feminine from masculine, so higher values indicate more feminine \"loadings\" and lower values are more \"masculine.\"\n",
    "6. Using the bias score vectors, where it is (job title, bias score), we create a new dataframe to store these vectors.\n",
    "7. We then use this dataframe to create a correlation graph between the biases seen in the study and our bias scores.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "mBERT = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_japanese = [\n",
    "    ('彼', '彼女'),  # he, she or boyfriend, girlfriend\n",
    "    ('彼の', '彼女の'),  # his, her\n",
    "    ('男性', '女性'),  # male, female\n",
    "    ('男の子', '女の子'),  # boy, girl\n",
    "    ('父', '母'),  # father, mother\n",
    "]\n",
    "\n",
    "pairs_spanish =  [\n",
    "    ('él', 'ella'),  # he, she\n",
    "    ('su', 'su'),     # his, her (Note: Spanish has the same word for his and her)\n",
    "    ('hombre', 'mujer'),  # man, woman\n",
    "    ('padre', 'madre'),   # father, mother\n",
    "    ('niño', 'niña'),     # boy, girl\n",
    "    ('actor', 'actriz'),  # actor (male), actress (female)\n",
    "    ('rey', 'reina'),     # king, queen\n",
    "    ('hermano', 'hermana')\n",
    "]\n",
    "# brother, sister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word embeddings from mBERT and create endpoints\n",
    "def mBERT_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = mBERT(**inputs)\n",
    "    # Take the mean of the embeddings across the token sequence to get a single embedding vector\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy().reshape(1,-1)\n",
    "    \n",
    "def mBERT_endpoints(vectors): # get difference vectors between pairs, create endpoints\n",
    "    diff_vectors = [normalize(mBERT_embeddings(x).reshape(1, -1) - mBERT_embeddings(y).reshape(1, -1))[0] for x, y in vectors] #model(x) gets word embeddings from model\n",
    "    return diff_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mBERT_vectors = mBERT_endpoints(pairs_japanese)\n",
    "mBERT_vectors # create endpoints for Japanese masculine<->feminine words to use for subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pca = TruncatedSVD(n_components=1) # one gender dimension\n",
    "m_pca.fit(mBERT_vectors)\n",
    "#CONFUSED!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mBERT_vectors(model, vectors): # get unit circle vectors\n",
    "    uc_vectors = [normalize(mBERT_embeddings(word)).flatten() for word in vectors]\n",
    "    return uc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_vectors = compute_mBERT_vectors(mBERT, jobs)\n",
    "m_vectors # get number representations of jobs data with mBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This projects the job description vectors onto the gender subspace created by the PCA. \n",
    "# meaning each job vector is now represented by how much it aligns with the gender dimension derived from the Japanese word pairs\n",
    "mBERT_list = m_pca.transform(m_vectors).flatten() \n",
    "\n",
    "# pairs each projected value - the new value after pca transform \n",
    "# (indicating the job's alignment with the gender dimension) with its corresponding job description\n",
    "mBERT_zip = list(zip(mBERT_list, jobs))\n",
    "mBERT_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mBERT_df = pd.DataFrame(mBERT_zip, columns = [\"bias\", \"job\"]) # create jobs data frame\n",
    "mBERT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher is more feminine, Lower is more masculine\n",
    "correlation_plot(mBERT_df, df, \"bias\", \"gpt_white_F\", \"job\", \"spaCy vector bias, Bolukbasi method\", \"GPT vector bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mBERT_spanish = mBERT_endpoints(pairs_spanish)\n",
    "mBERT_spanishPca = TruncatedSVD(n_components = 1)\n",
    "mBERT_spanishPca.fit(mBERT_spanish)\n",
    "\n",
    "mBERT_spanish_jobs = compute_mBERT_vectors(mBERT, jobs)\n",
    "mBERT_spanish_list = list(zip(mBERT_spanishPca.transform(mBERT_spanish_jobs).flatten(), jobs))\n",
    "mBERT_spanish_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mBERT_spanish_df = pd.DataFrame(mBERT_spanish_list, columns = [\"bias\", \"job\"])\n",
    "mBERT_spanish_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher is more feminine, Lower is more masculine\n",
    "correlation_plot(mBERT_spanish_df, df, \"bias\", \"gpt_white_F\", \"job\", \"spaCy vector bias, Bolukbasi method\", \"GPT vector bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: JAPANESE JOBS\n",
    "pairs_japanese_jobs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "22bc9f29c608090ef5c32fffe2f8088bbf12d521771a2adf38594eceebc29062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
